version: 0.2
# env:
#   parameter-store:
#     PASS: "/CodeBuild/ACCESS_KEY"
phases:
  pre_build:
    
    commands:
      - export KUBECONFIG=$HOME/.kube/config
  #     # - echo "$PASS"
  #     # - echo $PASS > test.pem
  #     - echo "running Build Phase"
  #     - cd k8s
  #     - chmod 600 test.pem
  #     - ssh -o "StrictHostKeyChecking no" -i "test.pem" ec2-user@54.88.140.43
  build:
    commands:
      # - echo "running Build Phase"
      # - cd k8s    
      # - chmod 600 test.pem
      # # - echo "Cloning Github repo"
      # # - git clone https://github.com/AnonyIIMessiah/Fleetman_cicd.git
      # # - cd Fleetman_cicd/k8s
      # - chmod +x trial.sh
      # - ./trial.sh
      - echo "Setting Environment Variables related to AWS CLI for Kube Config Setup"          
      - CREDENTIALS=$(aws sts assume-role --role-arn $EKS_KUBECTL_ROLE_ARN --role-session-name codebuild-kubectl --duration-seconds 900)
      - export AWS_ACCESS_KEY_ID="$(echo ${CREDENTIALS} | jq -r '.Credentials.AccessKeyId')"
      - export AWS_SECRET_ACCESS_KEY="$(echo ${CREDENTIALS} | jq -r '.Credentials.SecretAccessKey')"
      - export AWS_SESSION_TOKEN="$(echo ${CREDENTIALS} | jq -r '.Credentials.SessionToken')"
      - export AWS_EXPIRATION=$(echo ${CREDENTIALS} | jq -r '.Credentials.Expiration')
      # Setup kubectl with our EKS Cluster              
      - echo "Update Kube Config"      
      - aws eks update-kubeconfig --name $EKS_CLUSTER_NAME
      # Apply changes to our Application using kubectl
      - echo "Apply changes to kube manifests"            
      - kubectl apply -f k8s/
      - echo "Completed applying changes to Kubernetes Objects"           
        
  post_build:
    commands:
      - echo "Build completed successfully"


